{"cells":[{"cell_type":"markdown","metadata":{"id":"rODm_dOvfDe5"},"source":["# Import Library"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install natsort"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V0EMyiTxe8m9","trusted":true},"outputs":[],"source":["import os, os.path as osp\n","from glob import glob\n","from natsort import os_sorted\n","from tqdm import tqdm\n","\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{},"source":["# Input parameter"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Input folder data\n","input_dir = '/kaggle/input/human-activity-recognition-har/HAR'\n","\n","# split train folder into train and validation\n","split_train = 0.8\n","\n","# Parameter for data segmentation\n","frame_len = 100\n","hop_len = 50\n","\n","# Parameter for models\n","epochs = 3\n","batch_size = 64"]},{"cell_type":"markdown","metadata":{"id":"r6RoaytNfE2L"},"source":["# Load csv path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ak71zi0gfDI7","trusted":true},"outputs":[],"source":["train_dir = input_dir + '/train'\n","test_dir = input_dir + '/test'\n","df_paths = glob(osp.join(train_dir, '*', '*.csv'))"]},{"cell_type":"markdown","metadata":{"id":"eQ5NqWvffok_"},"source":["# Visualize DataFrame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fe0baY5mfuqx","trusted":true},"outputs":[],"source":["def plot_activity(activity,df,start=0,stop=200):\n","    df = df.iloc[start:stop]\n","\n","    ax = df.plot(subplots=True,figsize=(16,12),title=activity+ ', Start Row: '+str(start)+' Stop row: '+str(stop)) # Plot accelerometer for the activity."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7pwUDGxCgFCb","trusted":true},"outputs":[],"source":["path = df_paths[0]\n","activity, filename = path.split('/')[-2:]\n","df = pd.read_csv(path)\n","plot_activity(activity, df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WwnwlzD-gzwD","trusted":true},"outputs":[],"source":["plot_activity(activity,df,100,500)"]},{"cell_type":"markdown","metadata":{"id":"r_WjO9nhipbu"},"source":["# Training, Validation Data"]},{"cell_type":"markdown","metadata":{"id":"EqmVV6yCiuCx"},"source":["We'll use 80% of the measurements for training and validation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fzE7RCZxiyq3","trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","dataset_paths = {'train': [], 'val': []}\n","\n","for activity_dir in glob(osp.join(train_dir, '*')):\n","    paths = glob(osp.join(activity_dir, '*.csv'))\n","    train_paths, val_paths = train_test_split(paths,test_size= (1-split_train ),random_state=42)\n","    dataset_paths['train'].extend(train_paths)\n","    dataset_paths['val'].extend(val_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aWgL10TRpmax","trusted":true},"outputs":[],"source":["len(dataset_paths['train']), len(dataset_paths['val'])"]},{"cell_type":"markdown","metadata":{"id":"VzPscG_nrTq6"},"source":["# Load Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nXdg7da0l9Yq","trusted":true},"outputs":[],"source":["def frame(x, frame_len, hop_len):\n","    '''Slice a 3D data array into (overlapping) frames.\n","\n","    Example\n","    --------\n","    >>> x = np.array([[0, 1, 2],\n","                      [10, 11, 12],\n","                      [20, 21, 22],\n","                      [30, 31, 32],\n","                      [40, 41, 42],\n","                      [50, 51, 52],\n","                      [60, 61, 62]])\n","    >>> frames = x.frame(x, 3, 2)\n","    >>> x.shape\n","    (7, 3)\n","    >>> frames.shape\n","    (3, 3, 3)\n","    '''\n","\n","    assert(x.shape[0] >= frame_len)\n","    assert(hop_len >= 1)\n","\n","    n_frames = 1 + (x.shape[0] - frame_len) // hop_len\n","    shape = (n_frames, frame_len, x.shape[1])\n","    strides = ((hop_len * x.strides[0],) + x.strides)\n","    return np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)"]},{"cell_type":"markdown","metadata":{"id":"eN0O2wFTpZ6o"},"source":["**Load and preprocess data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h7VIzRjQsH9T","trusted":true},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","\n","dataset_blocks = {'train': {'block': [], 'label': []},\n","                  'val': {'block': [], 'label': []}}\n","\n","for dataset in ['train', 'val']:\n","    paths = dataset_paths[dataset]\n","\n","    for path in paths:\n","        activity = path.split(os.sep)[-2]\n","        df = pd.read_csv(path)\n","\n","        # Preprocessing\n","        mms = StandardScaler()\n","        for feature in list(df.columns):\n","            df[feature] = mms.fit_transform(df[[feature]])\n","\n","        samples = frame(df.loc[:, ].values, frame_len, hop_len)\n","        labels = np.full(samples.shape[0], activity)\n","\n","        dataset_blocks[dataset]['block'].extend(samples)\n","        dataset_blocks[dataset]['label'].extend(labels)\n","\n","    dataset_blocks[dataset]['block'] = np.array(dataset_blocks[dataset]['block'])\n","    dataset_blocks[dataset]['label'] = np.array(dataset_blocks[dataset]['label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nE6xS_6rvcEg","trusted":true},"outputs":[],"source":["dataset_blocks['train']['block'].shape, dataset_blocks['val']['block'].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5OMDfGCpYsJ","trusted":true},"outputs":[],"source":["dataset_blocks['val']['label'][:10]"]},{"cell_type":"markdown","metadata":{"id":"kO4FrwpCpqfN"},"source":["**One Hot Encode Labels**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x9Y_2-IQtdYO","trusted":true},"outputs":[],"source":["LABELS = os_sorted([osp.split(path)[-1] for path in glob(osp.join(train_dir, '*'))])\n","LABELS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BUIWPez5pVmr","trusted":true},"outputs":[],"source":["for dataset in ['train', 'val']:\n","    labels = dataset_blocks[dataset]['label']\n","    one_hot_encoded = np.zeros((labels.size, len(LABELS)))\n","\n","    for i, label in enumerate(LABELS):\n","        index = np.where(labels == label)[0]\n","        one_hot_encoded[index, i] = 1\n","\n","    dataset_blocks[dataset]['label'] = one_hot_encoded"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YvOuQJXEqAXA","trusted":true},"outputs":[],"source":["dataset_blocks['val']['label'][:10]"]},{"cell_type":"markdown","metadata":{"id":"AEwElZHUqZ6W"},"source":["**Visualize**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vsQF2RIIqemv","trusted":true},"outputs":[],"source":["for dataset in ['train', 'val']:\n","    labels = dataset_blocks[dataset]['label']\n","\n","    labels_sum = labels.sum(axis=0)\n","\n","    # Plotting\n","    plt.bar(LABELS, labels_sum)\n","    plt.title(f'{dataset} label')\n","    plt.xlabel('Labels')\n","    plt.ylabel('Count')\n","    plt.xticks(rotation=0)\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"C2MH_QTsxTrc"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Z_2auNYxVfo","trusted":true},"outputs":[],"source":["# Get the input shape -> (samples, time steps, features)\n","X_train = dataset_blocks['train']['block']\n","Y_train = dataset_blocks['train']['label']\n","\n","n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], Y_train.shape[1]\n","print('n_timesteps: {}, n_features: {}, n_outputs: {}'.format(n_timesteps,n_features,n_outputs))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bknLNmlBxk7a","trusted":true},"outputs":[],"source":["import keras\n","from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPooling1D, Input, Dense, Dropout, Flatten"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1VKxuSaBxtba","trusted":true},"outputs":[],"source":["model = Sequential()\n","model.add(Input(shape=(n_timesteps,n_features)))\n","model.add(Conv1D(16, 8, activation='relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(n_outputs, activation='softmax'))\n","\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"HH_s_se90Qy5"},"source":["**Training**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"afSwRXZB0XZs","trusted":true},"outputs":[],"source":["model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","callbacks_list = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath= '/kaggle/working/best_cnn_model.weights.h5',\n","        monitor='val_loss', save_best_only=True, save_weights_only=True\n","    ),\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w0D15phn0Y_O","trusted":true},"outputs":[],"source":["history = model.fit(dataset_blocks['train']['block'],\n","                    dataset_blocks['train']['label'],\n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    validation_data=(dataset_blocks['val']['block'],\n","                                     dataset_blocks['val']['label']),\n","                    callbacks=callbacks_list,\n","                    verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pJgFrBQC1vBp","trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","history_dict = history.history\n","\n","acc = history_dict['accuracy']\n","val_acc = history_dict['val_accuracy']\n","loss = history_dict['loss']\n","val_loss = history_dict['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","# \"bo\" is for \"blue dot\"\n","plt.plot(epochs, loss, 'b', label='Training loss')\n","# b is for \"solid blue line\"\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Pf84tRbx0TFK"},"source":["**Validation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gaX8BKqf0dQB","trusted":true},"outputs":[],"source":["# evaluate model\n","loss, accuracy = model.evaluate(dataset_blocks['val']['block'],\n","                                dataset_blocks['val']['label'], batch_size=batch_size, verbose=0)\n","print(f'Loss : {loss}')\n","print(f'Accuracy: {accuracy}')"]},{"cell_type":"markdown","metadata":{"id":"ywf06y-g4bjt"},"source":["# Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RRLAne6S4fJQ","trusted":true},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","\n","answer_list = []\n","\n","for filename in tqdm(glob(test_dir + '/*.csv')):\n","      \n","    # Read test csv file\n","    df = pd.read_csv(filename)\n","\n","    # Preprocessing\n","    mms = StandardScaler()\n","    for feature in list(df.columns):\n","        df[feature] = mms.fit_transform(df[[feature]])\n","\n","    samples = df.loc[:, ].values\n","    \n","    # Predict\n","    y_pred_prob = model.predict(np.array(samples).reshape(-1,frame_len,n_features), verbose = 0)\n","    y_pred = np.argmax(y_pred_prob, axis=1)\n","    class_names = LABELS[y_pred[0]]\n","    \n","    value = (filename.split('/')[-1], class_names)\n","    answer_list.append(value)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pk7cabBgajmO","trusted":true},"outputs":[],"source":["import pandas as pd\n","column_name = ['id','class']\n","xml_df = pd.DataFrame(answer_list, columns=column_name)\n","xml_df.to_csv('/kaggle/working/submission_cnn.csv', index=None)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":9041089,"sourceId":82480,"sourceType":"competition"}],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
